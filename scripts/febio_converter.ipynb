{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import meshio as mio\n",
    "import json\n",
    "import os\n",
    "\n",
    "import meshplot as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmsh_dim_tags(points, cells, tags):\n",
    "    dim_tags = np.tile([3, 1], [points.shape[0], 1])\n",
    "    for i, cell in enumerate(cells):\n",
    "        for vi in cell:\n",
    "            dim_tags[vi, 1] = tags[i]\n",
    "    return dim_tags\n",
    "\n",
    "\n",
    "def gmsh_cell_tags(tags):\n",
    "    cell_tags = [[tags[0]]]\n",
    "    for tag in tags[1:]:\n",
    "        if tag == cell_tags[-1][-1]:\n",
    "            cell_tags[-1].append(tag)\n",
    "        else:\n",
    "            cell_tags.append([tag])\n",
    "    return cell_tags\n",
    "\n",
    "\n",
    "def split_cells_by_tags(tags, cells):\n",
    "    assert(len(tags) == len(cells))\n",
    "    split_cells = [[cells[0]]]\n",
    "    for i, tag in enumerate(tags[1:]):\n",
    "        if tag == tags[i]:\n",
    "            split_cells[-1].append(cells[i + 1])\n",
    "        else:\n",
    "            split_cells.append([cells[i + 1]])\n",
    "    return split_cells\n",
    "\n",
    "\n",
    "def save_msh(file, points, tets, tags):\n",
    "    dim_tags = gmsh_dim_tags(points, tets, tags)\n",
    "    cell_tags = gmsh_cell_tags(tags)\n",
    "\n",
    "    tmp = [(\"tetra\", np.array(cells)) for cells in split_cells_by_tags(tags, tets)]\n",
    "    # print([(\"tetra\", T)])\n",
    "    # [(\"tetra\", T)]\n",
    "\n",
    "\n",
    "    mesh = mio.Mesh(\n",
    "        points,\n",
    "        tmp,\n",
    "        point_data={\"gmsh:dim_tags\": dim_tags},\n",
    "        cell_data={\"gmsh:physical\": cell_tags, \"gmsh:geometrical\": cell_tags}\n",
    "    )\n",
    "\n",
    "    mio.write(file, mesh, binary=True, file_format=\"gmsh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_control(control, args):\n",
    "    if control is None:\n",
    "        return\n",
    "        \n",
    "    tsn = control.find(\"time_steps\")\n",
    "    ssn = control.find(\"step_size\")\n",
    "    an = control.find(\"analysis\")\n",
    "\n",
    "    \n",
    "    if tsn is not None and ssn is not None and an is not None:\n",
    "        if an.attrib[\"type\"] == \"dynamic\":\n",
    "            time_steps = int(tsn.text)\n",
    "            step_size = float(ssn.text)\n",
    "\n",
    "            args[\"time\"] = {\n",
    "                \"tend\": step_size * time_steps,\n",
    "                \"time_steps\": time_steps\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_materials(febio):\n",
    "    materials = {}\n",
    "\n",
    "    material_parent = febio.find(\"Material\")\n",
    "    \n",
    "    for material_node in material_parent.iter(\"material\"):\n",
    "        material = material_node.attrib[\"type\"]\n",
    "        mid = int(material_node.attrib[\"id\"])+1\n",
    "        \n",
    "        E = float(material_node.find(\"E\").text)\n",
    "        nu = float(material_node.find(\"v\").text)\n",
    "                  \n",
    "        if material_node.find(\"density\") is None:\n",
    "            rho = 1\n",
    "        else:\n",
    "            rho = float(material_node.find(\"density\").text)\n",
    "\n",
    "        mat = \"\"\n",
    "        if material == \"neo-Hookean\":\n",
    "            mat = \"NeoHookean\"\n",
    "        elif material == \"isotropic elastic\":\n",
    "            mat = \"LinearElasticity\"\n",
    "        else:\n",
    "            print(\"Unsupported material {}, reverting to isotropic elastic\".format(material))\n",
    "            mat = \"LinearElasticity\"\n",
    "            \n",
    "\n",
    "        materials[mid] = {\"id\": mid, \"E\": E, \"nu\": nu, \"rho\": rho, \"type\": mat}\n",
    "        \n",
    "    return materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nodes(geometry):\n",
    "    vertices = []\n",
    "    for nodes in geometry.iter(\"Nodes\"):\n",
    "        for child in nodes.iter(\"node\"):\n",
    "            pos_str = child.text\n",
    "            vs = pos_str.split(\",\")\n",
    "            assert(len(vs) == 3);\n",
    "            \n",
    "            vertices.append([float(vs[0]), float(vs[1]), float(vs[2])])\n",
    "\n",
    "\n",
    "    V = np.array(vertices)\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_elements(geometry, numV, materials):\n",
    "    els = []\n",
    "    nodes = []\n",
    "    mids = []\n",
    "    \n",
    "    order = 1\n",
    "    \n",
    "    is_hex = False\n",
    "    types = \"\"\n",
    "    \n",
    "    for elements in geometry.iter(\"Elements\"):\n",
    "        el_type = elements.attrib[\"type\"]\n",
    "        mid = int(elements.attrib[\"mat\"])+1\n",
    "\n",
    "        if el_type != \"tet4\" and el_type != \"tet10\" and el_type != \"tet20\" and el_type != \"hex8\":\n",
    "            print(\"Unsupported elemet type {}\".format(el_type))\n",
    "            continue\n",
    "\n",
    "\n",
    "        if len(types) == 0:\n",
    "            if el_type.startswith(\"tet\"):\n",
    "                types = \"tet\"\n",
    "            else:\n",
    "                types = \"hex\"\n",
    "        elif not el_type.startswith(types, 0):\n",
    "            print(\"Unsupported elemet type {} since the mesh contains also {}\".format(el_type, types))\n",
    "            continue\n",
    "\n",
    "        if el_type == \"tet4\":\n",
    "            order = max(1, order)\n",
    "        elif el_type == \"tet10\":\n",
    "            order = max(2, order)\n",
    "        elif el_type == \"tet20\":\n",
    "            order = max(3, order)\n",
    "        elif el_type == \"hex8\":\n",
    "            order = max(1, order)\n",
    "            is_hex = True\n",
    "                \n",
    "\n",
    "        for child in elements.iter(\"elem\"):\n",
    "                ids = child.text\n",
    "                tt = ids.split(\",\");\n",
    "                assert(len(tt) >= 4);\n",
    "                \n",
    "                node_size = 8 if is_hex else 4\n",
    "\n",
    "                els.append([])\n",
    "                \n",
    "                for n in range(node_size):\n",
    "                    els[-1].append(int(tt[n]) - 1)\n",
    "                    assert(els[-1][n] < numV)\n",
    "\n",
    "                nodes.append([])\n",
    "                mids.append(mid)\n",
    "                \n",
    "                for n in range(len(tt)):\n",
    "                    nodes[-1].append(int(tt[n]) - 1)\n",
    "\n",
    "                if el_type == \"tet10\":\n",
    "                    assert(len(nodes[-1]) == 10)\n",
    "                    nodes[-1][8], nodes[-1][9] = nodes[-1][9], nodes[-1][8]\n",
    "                elif el_type == \"tet20\":\n",
    "                    assert(len(nodes[-1]) == 20)\n",
    "                    nodes[-1][8], nodes[-1][9] = nodes[-1][9], nodes[-1][8]\n",
    "                    nodes[-1][10], nodes[-1][11] = nodes[-1][11], nodes[-1][10]\n",
    "                    nodes[-1][12], nodes[-1][15] = nodes[-1][15], nodes[-1][12]\n",
    "                    nodes[-1][13], nodes[-1][14] = nodes[-1][14], nodes[-1][13]\n",
    "                    nodes[-1][16], nodes[-1][19] = nodes[-1][19], nodes[-1][16]\n",
    "                    nodes[-1][17], nodes[-1][19] = nodes[-1][19], nodes[-1][17]\n",
    "\n",
    "\n",
    "    T = np.array(els)\n",
    "                \n",
    "    return T, np.array(mids), order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_node_sets(geometry):\n",
    "    nodes_set = {}\n",
    "    \n",
    "    for child in geometry.iter(\"NodeSet\"):\n",
    "        name = child.attrib[\"name\"]\n",
    "                \n",
    "        for nodeid in child.iter(\"node\"):\n",
    "            nid = int(nodeid.attrib[\"id\"])-1\n",
    "            nodes_set[nid] = name\n",
    "\n",
    "            \n",
    "    return nodes_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dirichlet(boundaries, nodes_set, dt):\n",
    "    allbc = {}\n",
    "    \n",
    "    names = [nodes_set[k] for k in nodes_set]\n",
    "    \n",
    "    result = np.zeros((len(nodes_set), 4))\n",
    "    result[:, 0] = np.array([k for k in node_set])\n",
    "    \n",
    "    for child in boundaries.iter(\"fix\"):\n",
    "        name = child.attrib[\"node_set\"]\n",
    "        \n",
    "        if not name in names:\n",
    "            print(\"Sideset {} not present, skipping\".format(name))\n",
    "            continue\n",
    "\n",
    "        bc = child.attrib[\"bc\"]\n",
    "        bcs = bc.split(\",\")\n",
    "\n",
    "        value = np.array([0.,0.,0.])\n",
    "\n",
    "        if not \"x\" in bcs:\n",
    "            value[0] = np.NAN\n",
    "        if not \"y\" in bcs:\n",
    "            value[1] = np.NAN\n",
    "        if not \"z\" in bcs:\n",
    "            value[2] = np.NAN\n",
    "\n",
    "        for i,k in enumerate(node_set):\n",
    "            if node_set[k] == name:\n",
    "                result[i, 1:] = value\n",
    "                                \n",
    "\n",
    "    for child in boundaries.iter(\"prescribe\"):\n",
    "        name = child.attrib[\"node_set\"]\n",
    "        if not name in names:\n",
    "            print(\"Sideset {} not present, skipping\".format(name))\n",
    "            continue\n",
    "\n",
    "        bc = child.attrib[\"bc\"]\n",
    "        bcs = bc.split(\",\")\n",
    "        val = float(child.find(\"scale\").text) * dt\n",
    "        value = np.array([val, val, val])\n",
    "        \n",
    "        if not \"x\" in bcs:\n",
    "            value[0] = np.NAN\n",
    "        if not \"y\" in bcs:\n",
    "            value[1] = np.NAN\n",
    "        if not \"z\" in bcs:\n",
    "            value[2] = np.NAN\n",
    "\n",
    "        for i,k in enumerate(node_set):\n",
    "            if node_set[k] == name:\n",
    "                result[i, 1:] = value\n",
    "\n",
    "\n",
    "#             for (const tinyxml2::XMLElement *child = boundaries->FirstChildElement(\"vector_bc\"); child != NULL; child = child->NextSiblingElement(\"vector_bc\"))\n",
    "#             {\n",
    "#                 const std::string name = std::string(child->Attribute(\"node_set\"));\n",
    "#                 if (names.find(name) == names.end())\n",
    "#                 {\n",
    "#                     logger().error(\"Sideset {} not present, skipping\", name);\n",
    "#                     continue;\n",
    "#                 }\n",
    "#                 const int id = names.at(name);\n",
    "#                 const std::string centers = resolve_path(std::string(child->Attribute(\"centers\")), root_file);\n",
    "#                 const std::string values = resolve_path(std::string(child->Attribute(\"values\")), root_file);\n",
    "#                 const std::string rbf = \"thin_plate\"; //TODO\n",
    "#                 const double eps = 1e-3;              //TODO\n",
    "#                 //TODO add is x,y,z\n",
    "\n",
    "#                 Eigen::MatrixXd centers_mat, values_mat;\n",
    "#                 read_matrix(centers, centers_mat);\n",
    "#                 read_matrix(values, values_mat);\n",
    "\n",
    "#                 RBFInterpolation interp(values_mat, centers_mat, rbf, eps);\n",
    "#                 logger().trace(\"adding vector Dirichlet id={} centers={} values={} rbf={} eps={}\", id, centers, values, rbf, eps);\n",
    "\n",
    "#                 gproblem.add_dirichlet_boundary(\n",
    "#                     id, [interp](double x, double y, double z, double t) {\n",
    "#                         Eigen::Matrix<double, 3, 1> v;\n",
    "#                         v[0] = x;\n",
    "#                         v[1] = y;\n",
    "#                         v[2] = z;\n",
    "#                         return interp.interpolate(v);\n",
    "#                     },\n",
    "#                     true, true, true, get_interpolation(gproblem.is_time_dependent()));\n",
    "#             }\n",
    "\n",
    "#             const bool is_time_dept = gproblem.is_time_dependent();\n",
    "#             for (const tinyxml2::XMLElement *child = boundaries->FirstChildElement(\"scaling\"); child != NULL; child = child->NextSiblingElement(\"scaling\"))\n",
    "#             {\n",
    "#                 const std::string centres = std::string(child->Attribute(\"center\"));\n",
    "#                 const std::string factors = std::string(child->Attribute(\"factor\"));\n",
    "#                 const std::string name = std::string(child->Attribute(\"node_set\"));\n",
    "#                 if (names.find(name) == names.end())\n",
    "#                 {\n",
    "#                     logger().error(\"Sideset {} not present, skipping\", name);\n",
    "#                     continue;\n",
    "#                 }\n",
    "#                 const int id = names.at(name);\n",
    "\n",
    "#                 const auto centrec = StringUtils::split(centres, \",\");\n",
    "#                 if (centrec.size() != 3)\n",
    "#                 {\n",
    "#                     logger().error(\"Skipping scaling, center is not 3d\");\n",
    "#                     continue;\n",
    "#                 }\n",
    "#                 const Eigen::Vector3d center(\n",
    "#                     atof(centrec[0].c_str()),\n",
    "#                     atof(centrec[1].c_str()),\n",
    "#                     atof(centrec[2].c_str()));\n",
    "\n",
    "#                 const double scaling = atof(factors.c_str());\n",
    "#                 logger().trace(\"adding scaling Dirichlet id={} center=({}) scaling={}\", id, center.transpose(), scaling);\n",
    "#                 gproblem.add_dirichlet_boundary(\n",
    "#                     id, [center, scaling, is_time_dept](double x, double y, double z, double t) {\n",
    "#                         Eigen::Matrix<double, 3, 1> v;\n",
    "#                         Eigen::Matrix<double, 3, 1> target;\n",
    "#                         v[0] = x;\n",
    "#                         v[1] = y;\n",
    "#                         v[2] = z;\n",
    "#                         target = v;\n",
    "\n",
    "#                         const double s = is_time_dept ? (scaling * t) : scaling;\n",
    "#                         target -= center;\n",
    "#                         target *= s;\n",
    "#                         target += center;\n",
    "#                         return (target - v).eval();\n",
    "#                     },\n",
    "#                     true, true, true);\n",
    "#             }\n",
    "#         }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_neumann(loads, names, dt):\n",
    "    result = []\n",
    "    \n",
    "    if loads is None:\n",
    "        return result\n",
    "    \n",
    "    for child in loads.iter(\"surface_load\"):\n",
    "        name = child.attrib[\"surface\"]\n",
    "        btype = child.attrib[\"type\"]\n",
    "        assert(name in names)\n",
    "        \n",
    "        if btype == \"traction\":\n",
    "            traction = child.find(\"traction\").text\n",
    "            scalev = np.array([1., 1., 1.])\n",
    "            \n",
    "            for scale in child.iter(\"scale\"):\n",
    "                scales = scale.text\n",
    "                scalev *= float(scales)\n",
    "\n",
    "\n",
    "            bcs = traction.split(\",\")\n",
    "            assert(len(bcs) == 3)\n",
    "\n",
    "            force = np.array([float(v) for v in bcs])\n",
    "            force *= scalev*dt\n",
    "            \n",
    "            \n",
    "            print(\"adding Neumann id={} force=({})\".format(names[name], force))\n",
    "\n",
    "            result.append({\n",
    "                \"type\": \"neumann\",\n",
    "                \"id\": names[name],\n",
    "                \"value\": force\n",
    "                #get_interpolation(gproblem.is_time_dependent())\n",
    "            })\n",
    "        \n",
    "        elif btype == \"pressure\":\n",
    "            pressures = child.find(\"pressure\").text\n",
    "            \n",
    "            # TODO added minus here\n",
    "            pressure = -float(pressures) * dt\n",
    "\n",
    "            print(\"adding Pressure id={} pressure={}\".format(names[name], pressure))\n",
    "                        \n",
    "            result.append({\n",
    "                \"type\": \"pressure\",\n",
    "                \"id\": names[name],\n",
    "                \"value\": pressure\n",
    "                #get_interpolation(gproblem.is_time_dependent())\n",
    "            })\n",
    "        else:\n",
    "            print(\"Unsupported surface load {}\".format(btype))\n",
    "\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_surface_selection(geometry):\n",
    "    n_id = 1\n",
    "    names = {}\n",
    "    \n",
    "    selections = []\n",
    "    \n",
    "    for child in geometry.iter(\"Surface\"):\n",
    "        name = child.attrib[\"name\"]\n",
    "        names[name] = n_id;\n",
    "        \n",
    "\n",
    "        # TODO  only tri3\n",
    "        for nodeid in child.iter(\"tri3\"):\n",
    "            ids = nodeid.text\n",
    "            tt = ids.split(\",\")\n",
    "            assert(len(tt) == 3)\n",
    "            \n",
    "            selections.append([n_id] + [int(v) - 1 for v in tt])\n",
    "\n",
    "        for nodeid in child.iter(\"quad4\"):\n",
    "            ids = nodeid.text\n",
    "            tt = ids.split(\",\")\n",
    "            assert(len(tt) == 4)\n",
    "\n",
    "            tmp.append([int(v) - 1 for v in tt])\n",
    "\n",
    "        n_id += 1\n",
    "            \n",
    "    return np.array(selections), names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = \"\"\n",
    "dhat = 0.001\n",
    "output = \"sim.vtu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_json = {}\n",
    "output_json[\"output\"] = {\n",
    "    \"json\": \"sim.json\",\n",
    "    \"paraview\": {\n",
    "            \"file_name\": output,\n",
    "            \"surface\": True,\n",
    "            \"options\": {\n",
    "                \"material\": True,\n",
    "                \"body_ids\": True\n",
    "            },\n",
    "            \"vismesh_rel_area\": 10000000\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding Neumann id=1 force=([0. 0. 1.])\n"
     ]
    }
   ],
   "source": [
    "# tree = ET.parse(\"../data/test.feb\")\n",
    "tree = ET.parse(\"../data/lin-neo.feb\")\n",
    "\n",
    "root = tree.getroot()\n",
    "\n",
    "if root.attrib[\"version\"] != \"2.5\":\n",
    "    assert(False)\n",
    "    \n",
    "control = root.find(\"Control\")\n",
    "load_control(control, output_json)\n",
    "\n",
    "dt = 1\n",
    "\n",
    "if \"time\" in output_json:\n",
    "    dt = output_json[\"time\"][\"time_steps\"]\n",
    "\n",
    "materials = load_materials(root)\n",
    "\n",
    "    \n",
    "geometry = root.find(\"Geometry\");\n",
    "\n",
    "V = load_nodes(geometry)\n",
    "T, mids, order = load_elements(geometry, V.shape[0], {})\n",
    "\n",
    "node_set = load_node_sets(geometry)\n",
    "\n",
    "\n",
    "boundaries = root.find(\"Boundary\");\n",
    "dirichlet = load_dirichlet(boundaries, node_set, dt)\n",
    "\n",
    "surfs, names = load_surface_selection(geometry)\n",
    "loads = root.find(\"Loads\")\n",
    "neumann = load_neumann(loads, names, dt)\n",
    "\n",
    "\n",
    "has_collisions = geometry.find(\"SurfacePair\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################################################\n",
    "################## Output ###########################\n",
    "#####################################################\n",
    "\n",
    "if has_collisions:\n",
    "    output_json[\"contact\"] = {\n",
    "        \"enabled\": True,\n",
    "        \"dhat\": dhat\n",
    "    }\n",
    "\n",
    "\n",
    "output_json[\"materials\"] = [materials[k] for k in materials] if len(materials) > 1 else list(materials.values())[0]\n",
    "output_json[\"boundary_conditions\"] = {}\n",
    "\n",
    "\n",
    "output_json[\"geometry\"] = {\n",
    "    \"mesh\": os.path.join(out_folder,\"mesh.msh\"),\n",
    "    \"surface_selection\": \"\" if surfs.size <= 0 else os.path.join(out_folder,\"surfaces.txt\")\n",
    "}\n",
    "\n",
    "if surfs.size > 0:\n",
    "    np.savetxt(os.path.join(out_folder,\"surfaces.txt\"), surfs, fmt='%d')\n",
    "\n",
    "save_msh(os.path.join(out_folder,\"mesh.msh\"), V, T, mids)\n",
    "\n",
    "if dirichlet.size > 0:\n",
    "    output_json[\"boundary_conditions\"][\"dirichlet_boundary\"] = [os.path.join(out_folder,\"dirichlet.txt\")]\n",
    "    \n",
    "    np.savetxt(os.path.join(out_folder,\"dirichlet.txt\"), dirichlet)\n",
    "    \n",
    "output_json[\"boundary_conditions\"][\"rhs\"] = [0,0,0]\n",
    "\n",
    "with open(os.path.join(out_folder, \"sim.json\"), \"w\") as f:\n",
    "    f.write(json.dumps(output_json, indent=\"  \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1714 418 1482\r\n",
      "1 2210 1472 211\r\n",
      "1 766 1683 1483\r\n",
      "1 1391 2163 1390\r\n",
      "1 1758 1953 1481\r\n",
      "1 1461 458 1620\r\n",
      "1 1156 2163 1391\r\n",
      "1 1156 1384 2163\r\n",
      "1 1208 870 1377\r\n",
      "1 5 870 1208\r\n",
      "1 1274 942 1392\r\n",
      "1 1392 942 1214\r\n",
      "1 1071 1382 427\r\n",
      "1 1405 2112 1470\r\n",
      "1 1275 1405 1470\r\n",
      "1 2223 1161 1385\r\n",
      "1 975 1395 1399\r\n",
      "1 1402 871 1587\r\n",
      "1 1385 1161 1384\r\n",
      "1 1391 2272 975\r\n",
      "1 1382 1384 1628\r\n",
      "1 1418 1715 1377\r\n",
      "1 1492 1475 211\r\n",
      "1 211 1475 1614\r\n",
      "1 1377 1388 1106\r\n",
      "1 1461 1620 1082\r\n",
      "1 1046 1619 1461\r\n",
      "1 1619 458 1461\r\n",
      "1 1393 1387 1214\r\n",
      "1 766 1676 1404\r\n",
      "1 1470 1472 2274\r\n",
      "1 1470 1611 1472\r\n",
      "1 1481 2275 1758\r\n",
      "1 1214 1387 2271\r\n",
      "1 1385 1156 1266\r\n",
      "1 1292 1488 1611\r\n",
      "1 1470 1292 1611\r\n",
      "1 1676 1483 1958\r\n",
      "1 1485 1561 2112\r\n",
      "1 1392 1214 1266\r\n",
      "1 1402 1587 766\r\n",
      "1 1402 766 1404\r\n",
      "1 766 1483 1676\r\n",
      "1 1476 1680 1389\r\n",
      "1 920 1382 1071\r\n",
      "1 1614 418 211\r\n",
      "1 1470 2112 1292\r\n",
      "1 1405 1216 1404\r\n",
      "1 1404 1127 1405\r\n",
      "1 2163 1406 1797\r\n",
      "1 2 1071 2316\r\n",
      "1 1161 1628 1384\r\n",
      "1 2223 1385 1250\r\n",
      "1 1371 1994 1250\r\n",
      "1 1082 1620 1829\r\n",
      "1 2274 1472 1465\r\n",
      "1 1363 1161 1364\r\n",
      "1 1680 1208 1106\r\n",
      "1 1465 1082 2274\r\n",
      "1 1399 1275 1401\r\n",
      "1 1404 1395 1775\r\n",
      "1 1775 1395 1394\r\n",
      "1 1413 1364 1414\r\n",
      "1 1628 1363 1412\r\n",
      "1 1363 1413 1412\r\n",
      "1 1411 1394 1295\r\n",
      "1 942 1393 1214\r\n",
      "1 1406 1382 920\r\n",
      "1 1412 427 1628\r\n",
      "1 1363 1364 1413\r\n",
      "1 1415 1371 1417\r\n",
      "1 1415 1994 1371\r\n",
      "1 1418 1377 870\r\n",
      "1 1082 1401 2274\r\n",
      "1 1082 1829 1401\r\n",
      "1 1478 2165 1046\r\n",
      "1 1412 1836 427\r\n",
      "1 1478 1046 1758\r\n",
      "1 1492 1611 1488\r\n",
      "1 1715 1417 1371\r\n",
      "1 1418 1417 1715\r\n",
      "1 8 1587 871\r\n",
      "1 1208 1680 5\r\n",
      "1 1292 2112 1561\r\n",
      "1 1395 1216 1399\r\n",
      "1 1216 2273 1399\r\n",
      "1 1710 1614 11\r\n",
      "1 418 1614 1710\r\n",
      "1 1404 1676 1127\r\n",
      "1 1587 8 1683\r\n",
      "1 1561 1488 1292\r\n",
      "1 1274 1393 942\r\n",
      "1 1829 1393 1274\r\n",
      "1 418 1710 1482\r\n",
      "1 1465 1472 1714\r\n",
      "1 1388 458 1619\r\n",
      "1 1399 1401 1274\r\n",
      "1 1399 1274 1392\r\n",
      "1 1275 1470 2274\r\n",
      "1 1275 2274 1401\r\n",
      "1 1408 1394 2272\r\n",
      "1 1394 1408 1295\r\n",
      "1 1395 1404 1216\r\n",
      "1 2163 1384 1382\r\n",
      "1 1250 2271 1387\r\n",
      "1 1715 1387 1388\r\n",
      "1 1680 1106 1389\r\n",
      "1 1266 1156 1392\r\n",
      "1 1392 1156 1391\r\n",
      "1 1411 871 1402\r\n",
      "1 1620 1393 1829\r\n",
      "1 1106 1388 1389\r\n",
      "1 1714 1482 1481\r\n",
      "1 1714 1481 1953\r\n",
      "1 1395 2272 1394\r\n",
      "1 975 2272 1395\r\n",
      "1 1401 1829 1274\r\n",
      "1 1390 2163 1797\r\n",
      "1 1363 1628 1161\r\n",
      "1 920 1071 2\r\n",
      "1 1836 2 2316\r\n",
      "1 1266 1214 1385\r\n",
      "1 1214 2271 1385\r\n",
      "1 418 2210 211\r\n",
      "1 418 1714 2210\r\n",
      "1 1389 1619 1046\r\n",
      "1 1377 1715 1388\r\n",
      "1 1478 1758 2275\r\n",
      "1 1994 1364 1250\r\n",
      "1 1414 1994 1415\r\n",
      "1 1994 1414 1364\r\n",
      "1 1392 975 1399\r\n",
      "1 1391 1390 2272\r\n",
      "1 1758 1046 1461\r\n",
      "1 1758 1465 1953\r\n",
      "1 1611 211 1472\r\n",
      "1 1620 458 1393\r\n",
      "1 1399 2273 1275\r\n",
      "1 1127 1958 2112\r\n",
      "1 1958 1485 2112\r\n",
      "1 1411 1402 1775\r\n",
      "1 1402 1404 1775\r\n",
      "1 458 1387 1393\r\n",
      "1 1388 1387 458\r\n",
      "1 766 1587 1683\r\n",
      "1 1411 1775 1394\r\n",
      "1 1127 2112 1405\r\n",
      "1 1364 2223 1250\r\n",
      "1 1161 2223 1364\r\n",
      "1 1387 1715 1371\r\n",
      "1 1371 1250 1387\r\n",
      "1 1405 2273 1216\r\n",
      "1 2273 1405 1275\r\n",
      "1 1385 1384 1156\r\n",
      "1 1465 1461 1082\r\n",
      "1 1461 1465 1758\r\n",
      "1 1611 1492 211\r\n",
      "1 1714 1953 1465\r\n",
      "1 1208 1377 1106\r\n",
      "1 1476 1389 2165\r\n",
      "1 2165 1389 1046\r\n",
      "1 1389 1388 1619\r\n",
      "1 1406 2163 1382\r\n",
      "1 1392 1391 975\r\n",
      "1 1250 1385 2271\r\n",
      "1 1408 2272 1390\r\n",
      "1 1676 1958 1127\r\n",
      "1 1483 1485 1958\r\n",
      "1 1390 1797 1408\r\n",
      "1 2210 1714 1472\r\n",
      "1 2316 1071 427\r\n",
      "1 1836 2316 427\r\n",
      "1 427 1382 1628\r\n"
     ]
    }
   ],
   "source": [
    "!cat surfaces.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd=surfs[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([350, 438]),)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(1106 == T[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.67464407,  0.74126373,  3.        ])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V[1106,:], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(T, c):\n",
    "    f = np.ndarray([T.shape[0]*4, 3], dtype=T.dtype)\n",
    "    outc = np.ndarray([T.shape[0]*4], dtype=c.dtype)\n",
    "    \n",
    "    for i in range(T.shape[0]):\n",
    "        f[i*4+0] = np.array([T[i][1], T[i][0], T[i][2]])\n",
    "        f[i*4+1] = np.array([T[i][0], T[i][1], T[i][3]])\n",
    "        f[i*4+2] = np.array([T[i][1], T[i][2], T[i][3]])\n",
    "        f[i*4+3] = np.array([T[i][2], T[i][0], T[i][3]])\n",
    "        \n",
    "        outc[i*4:i*4+4] = c[i]\n",
    "        \n",
    "    return f, outc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, c = convert(T, mids)\n",
    "mp.plot(V, f, c, shading={\"point_size\": 1, \"wireframe\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? mio.Mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.find(\"Globals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
